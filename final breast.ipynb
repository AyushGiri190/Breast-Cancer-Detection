{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "186c20e7",
      "metadata": {
        "id": "186c20e7"
      },
      "outputs": [],
      "source": [
        "#These are Python libraries being imported for use in the code.\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "from shutil import copyfile\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c06bf8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "d4c06bf8",
        "outputId": "c7a0c487-cb85-42ed-ce3c-4e4f29801a24"
      },
      "outputs": [],
      "source": [
        "#This code is reading a CSV file named \"train.csv\" and selecting only the columns \"image_id\" and \"cancer\" from the file. The resulting dataframe is assigned to the variable \"df\". The \".head()\" method is then used to display the first few rows of the dataframe.\n",
        "df = pd.read_csv('./train.csv')[['image_id','cancer']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b1c7e2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b1c7e2e",
        "outputId": "df67f9c2-be88-48bf-c170-687bd7ba17f7"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q4QG9Qsdztiq",
      "metadata": {
        "id": "q4QG9Qsdztiq"
      },
      "outputs": [],
      "source": [
        "'''This code is creating a dictionary called `class_dict` with two keys, 0 and 1, each initialized with an empty list.\n",
        "It then iterates through each row of a pandas DataFrame called `df`. If the value in the 'cancer' column of the current \n",
        "row is 0, it appends the string representation of the 'image_id' column value with the extension '.png' to the list \n",
        "associated with the key 0 in `class_dict`. If the value in the 'cancer' column is not 0 (i.e. it is 1), \n",
        "it appends the same string representation of the 'image_id' column value with the extension '.png' to the list \n",
        "associated with the key 1 in `class_dict`. This code is essentially grouping the image IDs in `df` by their \n",
        "corresponding cancer class (0 or 1) and storing them in a dictionary for later use.'''\n",
        "class_dict = {0:[],1:[]}\n",
        "for n,i in df.iterrows():\n",
        "  if(i['cancer']==0):\n",
        "      class_dict[0].append(str(i['image_id'])+'.png')\n",
        "  else:\n",
        "      class_dict[1].append(str(i['image_id'])+'.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fbe8490",
      "metadata": {
        "id": "0fbe8490"
      },
      "outputs": [],
      "source": [
        "#making new directory for working purpose\n",
        "os.mkdir('./working')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "980723c9",
      "metadata": {
        "id": "980723c9"
      },
      "outputs": [],
      "source": [
        "'''This code is recursively searching for all files with the extension \".png\" in the directory \"./train_images\" \n",
        "and its subdirectories. It then copies each of these files to the directory \"./working\" with the same filename. \n",
        "The `os.walk()` function is used to traverse the directory tree and `shutil.copy()` is used to copy the files.'''\n",
        "root_dir = './train_images'\n",
        "dest_dir = './working'\n",
        "for subdir, dirs, files in os.walk(root_dir):\n",
        "    for file in files:\n",
        "        # Check if the file is a txt file\n",
        "        if file.endswith('.png'):\n",
        "            # Construct the source and destination file paths\n",
        "            src_path = os.path.join(subdir, file)\n",
        "            dest_path = os.path.join(dest_dir, file)\n",
        "\n",
        "            # Copy the file to the destination directory\n",
        "            shutil.copy(src_path, dest_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wec5-AEd5qOc",
      "metadata": {
        "id": "Wec5-AEd5qOc"
      },
      "outputs": [],
      "source": [
        "#Make new directories for the two classes of the prediction \n",
        "os.mkdir('./no')\n",
        "os.mkdir('./yes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zdFRfbJ55kQl",
      "metadata": {
        "id": "zdFRfbJ55kQl"
      },
      "outputs": [],
      "source": [
        "# initializing the varibales wiht the corresponding directories\n",
        "no_cancer = './no'\n",
        "cancer = './yes'\n",
        "source = './working'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tkVAhzA35Bfh",
      "metadata": {
        "id": "tkVAhzA35Bfh"
      },
      "outputs": [],
      "source": [
        "'''This code is iterating through a dictionary called `class_dict` and copying files from a source directory to two\n",
        "different destination directories based on the value of the key in the dictionary. If the key is 0, the file is copied\n",
        "to the `no_cancer` directory, and if the key is not 0, the file is copied to the `cancer` directory. The `shutil.copy()` \n",
        "function is used to copy the files.'''\n",
        "\n",
        "for k in class_dict:\n",
        "  if (k==0):\n",
        "    for v in class_dict[k]:\n",
        "        src_path = os.path.join(source, v)\n",
        "        dest_path = os.path.join(no_cancer, v)\n",
        "\n",
        "            # Copy the file to the destination directory\n",
        "        shutil.copy(src_path, dest_path)\n",
        "  else:\n",
        "    for v in class_dict[k]:\n",
        "      src_path = os.path.join(source, v)\n",
        "      dest_path = os.path.join(cancer, v)\n",
        "\n",
        "            # Copy the file to the destination directory\n",
        "      shutil.copy(src_path, dest_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2925Hden-TFu",
      "metadata": {
        "id": "2925Hden-TFu"
      },
      "outputs": [],
      "source": [
        "#Making the final directory to store the result after augmentation\n",
        "os.mkdir('./final')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J2hcJYo9-hEj",
      "metadata": {
        "id": "J2hcJYo9-hEj"
      },
      "outputs": [],
      "source": [
        "'''This code is using the `ImageDataGenerator` class from the `tensorflow.keras.preprocessing.image` module to generate \n",
        "augmented images from a directory of input images. The `datagen` object is defined with various transformations such as \n",
        "rotation, shifting, flipping, and zooming. The code then loops through each image in the input directory, reads the image \n",
        "using `cv2.imread`, expands the dimensions of the image using `np.expand_dims`, and generates 45 augmented images using the\n",
        "`datagen.flow` method. The augmented images are saved to the output directory with the same filename prefix as the original\n",
        "image.'''\n",
        "\n",
        "#This part of code increases the number of images in the positive class equivalent to that of the ngative as the numbers largly differ\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "# Define the ImageDataGenerator with any required transformations\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    zoom_range=0.1,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# Define the directory containing the images\n",
        "directory = '/content/yes'\n",
        "\n",
        "# Define the output directory where the augmented images will be saved\n",
        "output_dir = './final'\n",
        "\n",
        "# Generate augmented images and save them to disk\n",
        "for filename in os.listdir(directory):\n",
        "    img_path = os.path.join(directory, filename)\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    #img = array_to_img(img_to_array(load_img(img_path)))\n",
        "\n",
        "    img = np.expand_dims(img,axis=0)\n",
        "\n",
        "    i = 0\n",
        "    for batch in datagen.flow(img, batch_size=1, save_to_dir=output_dir, save_prefix=filename, save_format='png'):\n",
        "        i += 1\n",
        "        if i >= 45:  # Generate and save 45 augmented images per input image\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-FAEL0UrzvNt",
      "metadata": {
        "id": "-FAEL0UrzvNt"
      },
      "outputs": [],
      "source": [
        "'''`shutil.rmtree('./final')` is a Python command that deletes a directory and all its contents recursively. \n",
        "In this case, it is deleting the directory named \"final\" and all its contents in the current working directory.'''\n",
        "shutil.rmtree('./final')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WouDWCpV3yrH",
      "metadata": {
        "id": "WouDWCpV3yrH"
      },
      "outputs": [],
      "source": [
        "#Creating all the required directories for the use\n",
        "os.mkdir('./train')\n",
        "os.mkdir('./test')\n",
        "os.mkdir('./val')\n",
        "os.mkdir('./train/0')\n",
        "os.mkdir('./train/1')\n",
        "os.mkdir('./test/0')\n",
        "os.mkdir('./test/1')\n",
        "os.mkdir('./val/0')\n",
        "os.mkdir('./val/1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x-ksSvzM1t0g",
      "metadata": {
        "id": "x-ksSvzM1t0g"
      },
      "outputs": [],
      "source": [
        "'''This code is splitting a dataset into training, testing, and validation sets and moving the files into their respective \n",
        "directories. It uses the `train_test_split` function from the `sklearn.model_selection` module to split the data into train\n",
        "and test sets, and then splits the train set again to create a validation set. It then uses the `shutil.move` function to\n",
        "move the files from the original directory to the appropriate train, test, or validation directory.'''\n",
        "# Done for negative class\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define your directories\n",
        "data_dir = '/content/no'\n",
        "train_dir = './train'\n",
        "test_dir = './test'\n",
        "val_dir = './val'\n",
        "# Split your data into train and test sets\n",
        "data_files = os.listdir(data_dir)\n",
        "train_files, test_files = train_test_split(data_files, test_size=0.2)\n",
        "train_files, val_files = train_test_split(train_files, test_size=0.2)\n",
        "# Move the files into their respective directories\n",
        "for filename in train_files:\n",
        "    src_path = os.path.join(data_dir, filename)\n",
        "    dst_path = os.path.join(train_dir, '0', filename)\n",
        "    shutil.move(src_path, dst_path)\n",
        "\n",
        "for filename in test_files:\n",
        "    src_path = os.path.join(data_dir, filename)\n",
        "    dst_path = os.path.join(test_dir,'0', filename)\n",
        "    shutil.move(src_path, dst_path)\n",
        "\n",
        "for filename in val_files:\n",
        "    src_path = os.path.join(data_dir, filename)\n",
        "    dst_path = os.path.join(val_dir,'0', filename)\n",
        "    shutil.move(src_path, dst_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kdUMa4oc3DGO",
      "metadata": {
        "id": "kdUMa4oc3DGO"
      },
      "outputs": [],
      "source": [
        "'''This code is splitting a dataset into training, testing, and validation sets and moving the files into their respective \n",
        "directories. It uses the `train_test_split` function from the `sklearn.model_selection` module to split the data into train\n",
        "and test sets, and then splits the train set again to create a validation set. It then uses the `shutil.move` function to\n",
        "move the files from the original directory to the appropriate train, test, or validation directory.'''\n",
        "# Done for the positive class\n",
        "\n",
        "# Define your directories\n",
        "data_dir = '/content/final'\n",
        "train_dir = './train'\n",
        "test_dir = './test'\n",
        "val_dir = './val'\n",
        "# Split your data into train and test sets\n",
        "data_files = os.listdir(data_dir)\n",
        "train_files, test_files = train_test_split(data_files, test_size=0.2)\n",
        "train_files, val_files = train_test_split(train_files, test_size=0.2)\n",
        "# Move the files into their respective directories\n",
        "for filename in train_files:\n",
        "    src_path = os.path.join(data_dir, filename)\n",
        "    dst_path = os.path.join(train_dir, '1', filename)\n",
        "    shutil.move(src_path, dst_path)\n",
        "\n",
        "for filename in test_files:\n",
        "    src_path = os.path.join(data_dir, filename)\n",
        "    dst_path = os.path.join(test_dir,'1', filename)\n",
        "    shutil.move(src_path, dst_path)\n",
        "\n",
        "for filename in val_files:\n",
        "    src_path = os.path.join(data_dir, filename)\n",
        "    dst_path = os.path.join(val_dir,'1', filename)\n",
        "    shutil.move(src_path, dst_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aa6d18a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aa6d18a",
        "outputId": "af32501e-9443-4238-9489-8e2a20f233bf"
      },
      "outputs": [],
      "source": [
        "# Data preprocessing\n",
        "# Train data\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagenerator = ImageDataGenerator(\n",
        "    rescale=1.0 / 255)\n",
        "train_generator = datagenerator.flow_from_directory(\n",
        "    directory='./train', target_size=(128,128), class_mode=\"categorical\", batch_size=32\n",
        ")\n",
        "\n",
        "# Validation data\n",
        "val_generator = datagenerator.flow_from_directory(\n",
        "    directory='./val', target_size=(128,128), class_mode=\"categorical\", batch_size=32\n",
        ")\n",
        "# Test data\n",
        "test_generator = datagenerator.flow_from_directory(\n",
        "    directory='./test', target_size=(128,128), class_mode=\"categorical\", batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69bb9d1a",
      "metadata": {
        "id": "69bb9d1a"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D,Dropout,MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28iVkCS9EE9m",
      "metadata": {
        "id": "28iVkCS9EE9m"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j9GYYzrDUCqP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9GYYzrDUCqP",
        "outputId": "19e478b0-1a28-4d65-dc80-9945a4018a0a"
      },
      "outputs": [],
      "source": [
        "# Initializing the VGG16 model\n",
        "vgg16_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(128,128, 3))\n",
        "\n",
        "for layer in vgg16_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Initialize a sequential model\n",
        "model2 = Sequential()\n",
        "model2.add(vgg16_model)\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(256, activation='relu'))\n",
        "model2.add(Dense(2, activation=\"softmax\"))\n",
        "#model.summary()\n",
        "model2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eec0a514",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eec0a514",
        "outputId": "859e26be-8def-43f7-bf2b-95aa18010a38"
      },
      "outputs": [],
      "source": [
        "# Fitting the model \n",
        "model2_history = model2.fit(train_generator,validation_data=val_generator,epochs=10, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EwdQqs0LUmEB",
      "metadata": {
        "id": "EwdQqs0LUmEB"
      },
      "outputs": [],
      "source": [
        "# Saving the model\n",
        "model2.save('vgg16.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ACd46Z_hT78P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "ACd46Z_hT78P",
        "outputId": "5c6eb18a-064c-4de9-c707-7ca74d0fbd08"
      },
      "outputs": [],
      "source": [
        "# plotting the accuracy and loss graph\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plot the training and validation accuracy\n",
        "plt.plot(model2_history.history['accuracy'])\n",
        "plt.plot(model2_history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# plot the training and validation loss\n",
        "plt.plot(model2_history.history['loss'])\n",
        "plt.plot(model2_history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a568c1fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "X ,y1 = test_generator.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lpwZ9W70F8kc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpwZ9W70F8kc",
        "outputId": "a201a13d-4aad-432b-cd45-a23465ad9bc2"
      },
      "outputs": [],
      "source": [
        "result2 = model2.evaluate(X,y1) # test loss and acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feD22YDhGKu1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feD22YDhGKu1",
        "outputId": "84d6cd61-1ee8-446a-f85c-94aa66e413ad"
      },
      "outputs": [],
      "source": [
        "print(result2[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Nr6SPygmsypg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr6SPygmsypg",
        "outputId": "e659e92f-635e-43cd-bd83-96bcf073970e"
      },
      "outputs": [],
      "source": [
        "y_pred1 = model2.predict(X1)\n",
        "y_temp=[]\n",
        "for i in range (21107):\n",
        "    y_temp.append(y_pred1[i].argmax())\n",
        "y_pred1 = np.array(y_temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qYM9m01Nsyj8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYM9m01Nsyj8",
        "outputId": "2d8f7337-762b-4ec1-bbbf-5137a2b6cfd1"
      },
      "outputs": [],
      "source": [
        "print(sklearn.metrics.classification_report(y_true,y_pred1,labels =None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uJTLdM0psyiR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJTLdM0psyiR",
        "outputId": "371969ac-2f14-469e-d850-17b1bf1db200"
      },
      "outputs": [],
      "source": [
        "cm2 = confusion_matrix(y_true,y_pred1)\n",
        "print(cm2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
